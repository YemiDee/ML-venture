{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d876aa",
   "metadata": {},
   "source": [
    "Introduction: The goal of this task is to predict the intent of the customer given their query text input. The dataset is ATIS (Airline Travel Information System) and consists of (query, intent) pairs. For this problem, you will implement the Bag of Word technique and a fully connected neural network to predict the intent of query text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37bf8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5a01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/atis.train.csv', delimiter=',')\n",
    "query_train, intent_train = df_train[\"tokens\"], df_train[\"intent\"]\n",
    "\n",
    "df_test = pd.read_csv('dataset/atis.test.csv', delimiter=',')\n",
    "query_test, intent_test = df_test[\"tokens\"], df_test[\"intent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20808d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query examples: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    BOS what is the cost of a round trip flight fr...\n",
       "1    BOS now i need a flight leaving fort worth and...\n",
       "2    BOS i need to fly from kansas city to chicago ...\n",
       "3           BOS what is the meaning of meal code s EOS\n",
       "4    BOS show me all flights from denver to pittsbu...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Query examples: \")\n",
    "query_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91686dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent examples: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         atis_airfare\n",
       "1          atis_flight\n",
       "2          atis_flight\n",
       "3    atis_abbreviation\n",
       "4          atis_flight\n",
       "Name: intent, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Intent examples: \")\n",
    "intent_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d401179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17 different categories of intent.\n",
      "['atis_airfare' 'atis_flight' 'atis_abbreviation' 'atis_ground_service'\n",
      " 'atis_restriction' 'atis_airport' 'atis_quantity' 'atis_meal'\n",
      " 'atis_airline' 'atis_city' 'atis_flight_no' 'atis_ground_fare'\n",
      " 'atis_flight_time' 'atis_flight#atis_airfare' 'atis_distance'\n",
      " 'atis_aircraft' 'atis_capacity']\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {:d} different categories of intent.\".format(intent_train.nunique()))\n",
    "print(intent_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cddc404a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((586,), (4274,), (586,), (4274,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_test.shape, intent_train.shape, query_test.shape, query_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c7f57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# TODO: Transform query_train and query_test into Bag of Word representations: X_train, X_test\n",
    "# Hint: Use sklearn CountVectorizer to construct Bag of Word representation for the query text.\n",
    "# Approximately 3 lines of code\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "# fit_vectorizer = vectorizer.fit(query_train)\n",
    "X_train = vectorizer.fit_transform(query_train).toarray()\n",
    "X_test = vectorizer.transform(query_test).toarray()\n",
    "\n",
    "\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29aa4ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cc0ba71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((586, 6992), (4274, 6992))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4eae09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "y_train = labelEncoder.fit_transform(intent_train)\n",
    "y_test = labelEncoder.transform(intent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3fe1ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4274,), (586,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "463d52fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# TODO: Train your favorite model and evaluate your model with the test data\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "193547be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:57:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test accuracy: 97.0 percent\n"
     ]
    }
   ],
   "source": [
    "xgb_model=XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "#fit xg boost model and predict\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# compute accuracy of predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print('Test accuracy:', round(accuracy, 2)*100, 'percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbec2b3",
   "metadata": {},
   "source": [
    "## Brief observation and conclusion\n",
    "Using an ngram_range of 1-2 as an additional argument in my count vectorizer function further increases my accuracy on the \n",
    "XGboost classifier from 96% to 97%, the ngram accounts for joint or contiguous words which makes sense together (some semantics).\n",
    "Without the ngrams, the number of trainable parameters is significantly less making XGboost less computationally expensive, but with the ngram\n",
    "argument, the XGB classifier took longer to run because of significant increase in trainable parameters. But the difference in accuracy gained isn't much. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888753e2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cecacdee79960deaff6922620289fbba3512fa0446a24cb89739189e06ed7e98"
  },
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
